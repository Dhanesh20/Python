{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\prashant\\Downloads\\train_ctrUa4K (1).csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Loan_ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['LoanAmount','Loan_Amount_Term']:\n",
    "    df[i].replace(0,np.nan,inplace=True)\n",
    "    df[i].fillna(df[i].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status']\n",
      "Numeric columns: ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = []\n",
    "numeric_columns = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        categorical_columns.append(col)\n",
    "    else:\n",
    "        numeric_columns.append(col)\n",
    "\n",
    "print(\"Categorical columns:\", categorical_columns)\n",
    "print(\"Numeric columns:\", numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_columns:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.363499</td>\n",
       "      <td>0.200692</td>\n",
       "      <td>0.044667</td>\n",
       "      <td>-0.007948</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.157993</td>\n",
       "      <td>0.102137</td>\n",
       "      <td>-0.088109</td>\n",
       "      <td>0.024682</td>\n",
       "      <td>-0.020576</td>\n",
       "      <td>0.052533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married</th>\n",
       "      <td>0.363499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375597</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>0.019750</td>\n",
       "      <td>0.040226</td>\n",
       "      <td>0.107327</td>\n",
       "      <td>0.181882</td>\n",
       "      <td>-0.110044</td>\n",
       "      <td>0.020519</td>\n",
       "      <td>0.029479</td>\n",
       "      <td>0.098560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents</th>\n",
       "      <td>0.200692</td>\n",
       "      <td>0.375597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039250</td>\n",
       "      <td>0.051180</td>\n",
       "      <td>0.124717</td>\n",
       "      <td>-0.010586</td>\n",
       "      <td>0.168145</td>\n",
       "      <td>-0.099282</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>0.016984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.044667</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>0.039250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014796</td>\n",
       "      <td>-0.142747</td>\n",
       "      <td>-0.067085</td>\n",
       "      <td>-0.171444</td>\n",
       "      <td>-0.112531</td>\n",
       "      <td>-0.075720</td>\n",
       "      <td>-0.033095</td>\n",
       "      <td>-0.088699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self_Employed</th>\n",
       "      <td>-0.007948</td>\n",
       "      <td>0.019750</td>\n",
       "      <td>0.051180</td>\n",
       "      <td>-0.014796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.167491</td>\n",
       "      <td>-0.012554</td>\n",
       "      <td>0.115941</td>\n",
       "      <td>-0.028340</td>\n",
       "      <td>-0.016306</td>\n",
       "      <td>-0.052259</td>\n",
       "      <td>-0.018705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.040226</td>\n",
       "      <td>0.124717</td>\n",
       "      <td>-0.142747</td>\n",
       "      <td>0.167491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.114302</td>\n",
       "      <td>0.490153</td>\n",
       "      <td>-0.007649</td>\n",
       "      <td>-0.044954</td>\n",
       "      <td>-0.066311</td>\n",
       "      <td>-0.042166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <td>0.157993</td>\n",
       "      <td>0.107327</td>\n",
       "      <td>-0.010586</td>\n",
       "      <td>-0.067085</td>\n",
       "      <td>-0.012554</td>\n",
       "      <td>-0.114302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.192269</td>\n",
       "      <td>-0.008529</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>-0.039323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoanAmount</th>\n",
       "      <td>0.102137</td>\n",
       "      <td>0.181882</td>\n",
       "      <td>0.168145</td>\n",
       "      <td>-0.171444</td>\n",
       "      <td>0.115941</td>\n",
       "      <td>0.490153</td>\n",
       "      <td>0.192269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049991</td>\n",
       "      <td>-0.027274</td>\n",
       "      <td>-0.113254</td>\n",
       "      <td>-0.062882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <td>-0.088109</td>\n",
       "      <td>-0.110044</td>\n",
       "      <td>-0.099282</td>\n",
       "      <td>-0.112531</td>\n",
       "      <td>-0.028340</td>\n",
       "      <td>-0.007649</td>\n",
       "      <td>-0.008529</td>\n",
       "      <td>0.049991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024302</td>\n",
       "      <td>-0.067434</td>\n",
       "      <td>0.004054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History</th>\n",
       "      <td>0.024682</td>\n",
       "      <td>0.020519</td>\n",
       "      <td>-0.039492</td>\n",
       "      <td>-0.075720</td>\n",
       "      <td>-0.016306</td>\n",
       "      <td>-0.044954</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>-0.027274</td>\n",
       "      <td>0.024302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003404</td>\n",
       "      <td>0.545934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Area</th>\n",
       "      <td>-0.020576</td>\n",
       "      <td>0.029479</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>-0.033095</td>\n",
       "      <td>-0.052259</td>\n",
       "      <td>-0.066311</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>-0.113254</td>\n",
       "      <td>-0.067434</td>\n",
       "      <td>-0.003404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Status</th>\n",
       "      <td>0.052533</td>\n",
       "      <td>0.098560</td>\n",
       "      <td>0.016984</td>\n",
       "      <td>-0.088699</td>\n",
       "      <td>-0.018705</td>\n",
       "      <td>-0.042166</td>\n",
       "      <td>-0.039323</td>\n",
       "      <td>-0.062882</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.545934</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Gender   Married  Dependents  Education  Self_Employed  \\\n",
       "Gender             1.000000  0.363499    0.200692   0.044667      -0.007948   \n",
       "Married            0.363499  1.000000    0.375597  -0.002516       0.019750   \n",
       "Dependents         0.200692  0.375597    1.000000   0.039250       0.051180   \n",
       "Education          0.044667 -0.002516    0.039250   1.000000      -0.014796   \n",
       "Self_Employed     -0.007948  0.019750    0.051180  -0.014796       1.000000   \n",
       "ApplicantIncome    0.035377  0.040226    0.124717  -0.142747       0.167491   \n",
       "CoapplicantIncome  0.157993  0.107327   -0.010586  -0.067085      -0.012554   \n",
       "LoanAmount         0.102137  0.181882    0.168145  -0.171444       0.115941   \n",
       "Loan_Amount_Term  -0.088109 -0.110044   -0.099282  -0.112531      -0.028340   \n",
       "Credit_History     0.024682  0.020519   -0.039492  -0.075720      -0.016306   \n",
       "Property_Area     -0.020576  0.029479   -0.000748  -0.033095      -0.052259   \n",
       "Loan_Status        0.052533  0.098560    0.016984  -0.088699      -0.018705   \n",
       "\n",
       "                   ApplicantIncome  CoapplicantIncome  LoanAmount  \\\n",
       "Gender                    0.035377           0.157993    0.102137   \n",
       "Married                   0.040226           0.107327    0.181882   \n",
       "Dependents                0.124717          -0.010586    0.168145   \n",
       "Education                -0.142747          -0.067085   -0.171444   \n",
       "Self_Employed             0.167491          -0.012554    0.115941   \n",
       "ApplicantIncome           1.000000          -0.114302    0.490153   \n",
       "CoapplicantIncome        -0.114302           1.000000    0.192269   \n",
       "LoanAmount                0.490153           0.192269    1.000000   \n",
       "Loan_Amount_Term         -0.007649          -0.008529    0.049991   \n",
       "Credit_History           -0.044954           0.000391   -0.027274   \n",
       "Property_Area            -0.066311           0.000368   -0.113254   \n",
       "Loan_Status              -0.042166          -0.039323   -0.062882   \n",
       "\n",
       "                   Loan_Amount_Term  Credit_History  Property_Area  \\\n",
       "Gender                    -0.088109        0.024682      -0.020576   \n",
       "Married                   -0.110044        0.020519       0.029479   \n",
       "Dependents                -0.099282       -0.039492      -0.000748   \n",
       "Education                 -0.112531       -0.075720      -0.033095   \n",
       "Self_Employed             -0.028340       -0.016306      -0.052259   \n",
       "ApplicantIncome           -0.007649       -0.044954      -0.066311   \n",
       "CoapplicantIncome         -0.008529        0.000391       0.000368   \n",
       "LoanAmount                 0.049991       -0.027274      -0.113254   \n",
       "Loan_Amount_Term           1.000000        0.024302      -0.067434   \n",
       "Credit_History             0.024302        1.000000      -0.003404   \n",
       "Property_Area             -0.067434       -0.003404       1.000000   \n",
       "Loan_Status                0.004054        0.545934       0.016778   \n",
       "\n",
       "                   Loan_Status  \n",
       "Gender                0.052533  \n",
       "Married               0.098560  \n",
       "Dependents            0.016984  \n",
       "Education            -0.088699  \n",
       "Self_Employed        -0.018705  \n",
       "ApplicantIncome      -0.042166  \n",
       "CoapplicantIncome    -0.039323  \n",
       "LoanAmount           -0.062882  \n",
       "Loan_Amount_Term      0.004054  \n",
       "Credit_History        0.545934  \n",
       "Property_Area         0.016778  \n",
       "Loan_Status           1.000000  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of 'Gender': -1.69\n",
      "Skewness of 'Married': -0.62\n",
      "Skewness of 'Dependents': 0.96\n",
      "Skewness of 'Education': 1.39\n",
      "Skewness of 'Self_Employed': 2.12\n",
      "Skewness of 'ApplicantIncome': 6.94\n",
      "Skewness of 'CoapplicantIncome': 5.93\n",
      "Skewness of 'LoanAmount': 2.43\n",
      "Skewness of 'Loan_Amount_Term': -2.37\n",
      "Skewness of 'Credit_History': -1.90\n",
      "Skewness of 'Property_Area': -0.05\n",
      "Skewness of 'Loan_Status': -0.77\n"
     ]
    }
   ],
   "source": [
    "for column, skew_val in skewness.items():\n",
    "    print(f\"Skewness of '{column}': {skew_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness of 'Gender' after transformation: -1.69\n",
      "Skewness of 'Married' after transformation: -0.62\n",
      "Skewness of 'Dependents' after transformation: 0.62\n",
      "Skewness of 'Education' after transformation: 1.39\n",
      "Skewness of 'Self_Employed' after transformation: 2.12\n",
      "Skewness of 'ApplicantIncome' after transformation: 0.89\n",
      "Skewness of 'CoapplicantIncome' after transformation: 0.58\n",
      "Skewness of 'LoanAmount' after transformation: -1.01\n",
      "Skewness of 'Loan_Amount_Term' after transformation: -2.37\n",
      "Skewness of 'Credit_History' after transformation: -1.90\n",
      "Skewness of 'Property_Area' after transformation: -0.05\n",
      "Skewness of 'Loan_Status' after transformation: -0.77\n"
     ]
    }
   ],
   "source": [
    "for column, skew_val in skewness.items():\n",
    "    if skew_val > 0.5:  # You can adjust this threshold as needed\n",
    "        df[column] = np.log1p(df[column])  # Applying log(1+x) transformation\n",
    "\n",
    "# Print skewness after transformation\n",
    "skewness_after = df.skew()\n",
    "for column, skew_val in skewness_after.items():\n",
    "    print(f\"Skewness of '{column}' after transformation: {skew_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                0\n",
       "Married               0\n",
       "Dependents            0\n",
       "Education             0\n",
       "Self_Employed         0\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           40\n",
       "Loan_Amount_Term      0\n",
       "Credit_History        0\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['LoanAmount','Loan_Amount_Term']:\n",
    "    df[i].replace(0,np.nan,inplace=True)\n",
    "    df[i].fillna(df[i].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.363499</td>\n",
       "      <td>0.198653</td>\n",
       "      <td>0.044667</td>\n",
       "      <td>-0.007948</td>\n",
       "      <td>0.048716</td>\n",
       "      <td>0.228805</td>\n",
       "      <td>0.130118</td>\n",
       "      <td>-0.088109</td>\n",
       "      <td>0.024682</td>\n",
       "      <td>-0.020576</td>\n",
       "      <td>0.052533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married</th>\n",
       "      <td>0.363499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.396187</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>0.019750</td>\n",
       "      <td>0.018413</td>\n",
       "      <td>0.245707</td>\n",
       "      <td>0.171627</td>\n",
       "      <td>-0.110044</td>\n",
       "      <td>0.020519</td>\n",
       "      <td>0.029479</td>\n",
       "      <td>0.098560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents</th>\n",
       "      <td>0.198653</td>\n",
       "      <td>0.396187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030597</td>\n",
       "      <td>0.067650</td>\n",
       "      <td>0.142643</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>0.124595</td>\n",
       "      <td>-0.104441</td>\n",
       "      <td>-0.032219</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.018981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.044667</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>0.030597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014796</td>\n",
       "      <td>-0.188659</td>\n",
       "      <td>-0.023280</td>\n",
       "      <td>-0.118730</td>\n",
       "      <td>-0.112531</td>\n",
       "      <td>-0.075720</td>\n",
       "      <td>-0.033095</td>\n",
       "      <td>-0.088699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self_Employed</th>\n",
       "      <td>-0.007948</td>\n",
       "      <td>0.019750</td>\n",
       "      <td>0.067650</td>\n",
       "      <td>-0.014796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.235503</td>\n",
       "      <td>-0.063461</td>\n",
       "      <td>0.118115</td>\n",
       "      <td>-0.028340</td>\n",
       "      <td>-0.016306</td>\n",
       "      <td>-0.052259</td>\n",
       "      <td>-0.018705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <td>0.048716</td>\n",
       "      <td>0.018413</td>\n",
       "      <td>0.142643</td>\n",
       "      <td>-0.188659</td>\n",
       "      <td>0.235503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.288727</td>\n",
       "      <td>0.416260</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>-0.073278</td>\n",
       "      <td>-0.007115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <td>0.228805</td>\n",
       "      <td>0.245707</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>-0.023280</td>\n",
       "      <td>-0.063461</td>\n",
       "      <td>-0.288727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202952</td>\n",
       "      <td>-0.005052</td>\n",
       "      <td>-0.003105</td>\n",
       "      <td>-0.050993</td>\n",
       "      <td>0.025545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoanAmount</th>\n",
       "      <td>0.130118</td>\n",
       "      <td>0.171627</td>\n",
       "      <td>0.124595</td>\n",
       "      <td>-0.118730</td>\n",
       "      <td>0.118115</td>\n",
       "      <td>0.416260</td>\n",
       "      <td>0.202952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028930</td>\n",
       "      <td>-0.005624</td>\n",
       "      <td>-0.151566</td>\n",
       "      <td>-0.001777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <td>-0.088109</td>\n",
       "      <td>-0.110044</td>\n",
       "      <td>-0.104441</td>\n",
       "      <td>-0.112531</td>\n",
       "      <td>-0.028340</td>\n",
       "      <td>-0.021801</td>\n",
       "      <td>-0.005052</td>\n",
       "      <td>0.028930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024302</td>\n",
       "      <td>-0.067434</td>\n",
       "      <td>0.004054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History</th>\n",
       "      <td>0.024682</td>\n",
       "      <td>0.020519</td>\n",
       "      <td>-0.032219</td>\n",
       "      <td>-0.075720</td>\n",
       "      <td>-0.016306</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>-0.003105</td>\n",
       "      <td>-0.005624</td>\n",
       "      <td>0.024302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003404</td>\n",
       "      <td>0.545934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Area</th>\n",
       "      <td>-0.020576</td>\n",
       "      <td>0.029479</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>-0.033095</td>\n",
       "      <td>-0.052259</td>\n",
       "      <td>-0.073278</td>\n",
       "      <td>-0.050993</td>\n",
       "      <td>-0.151566</td>\n",
       "      <td>-0.067434</td>\n",
       "      <td>-0.003404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Status</th>\n",
       "      <td>0.052533</td>\n",
       "      <td>0.098560</td>\n",
       "      <td>0.018981</td>\n",
       "      <td>-0.088699</td>\n",
       "      <td>-0.018705</td>\n",
       "      <td>-0.007115</td>\n",
       "      <td>0.025545</td>\n",
       "      <td>-0.001777</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.545934</td>\n",
       "      <td>0.016778</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Gender   Married  Dependents  Education  Self_Employed  \\\n",
       "Gender             1.000000  0.363499    0.198653   0.044667      -0.007948   \n",
       "Married            0.363499  1.000000    0.396187  -0.002516       0.019750   \n",
       "Dependents         0.198653  0.396187    1.000000   0.030597       0.067650   \n",
       "Education          0.044667 -0.002516    0.030597   1.000000      -0.014796   \n",
       "Self_Employed     -0.007948  0.019750    0.067650  -0.014796       1.000000   \n",
       "ApplicantIncome    0.048716  0.018413    0.142643  -0.188659       0.235503   \n",
       "CoapplicantIncome  0.228805  0.245707   -0.013889  -0.023280      -0.063461   \n",
       "LoanAmount         0.130118  0.171627    0.124595  -0.118730       0.118115   \n",
       "Loan_Amount_Term  -0.088109 -0.110044   -0.104441  -0.112531      -0.028340   \n",
       "Credit_History     0.024682  0.020519   -0.032219  -0.075720      -0.016306   \n",
       "Property_Area     -0.020576  0.029479    0.019520  -0.033095      -0.052259   \n",
       "Loan_Status        0.052533  0.098560    0.018981  -0.088699      -0.018705   \n",
       "\n",
       "                   ApplicantIncome  CoapplicantIncome  LoanAmount  \\\n",
       "Gender                    0.048716           0.228805    0.130118   \n",
       "Married                   0.018413           0.245707    0.171627   \n",
       "Dependents                0.142643          -0.013889    0.124595   \n",
       "Education                -0.188659          -0.023280   -0.118730   \n",
       "Self_Employed             0.235503          -0.063461    0.118115   \n",
       "ApplicantIncome           1.000000          -0.288727    0.416260   \n",
       "CoapplicantIncome        -0.288727           1.000000    0.202952   \n",
       "LoanAmount                0.416260           0.202952    1.000000   \n",
       "Loan_Amount_Term         -0.021801          -0.005052    0.028930   \n",
       "Credit_History            0.011250          -0.003105   -0.005624   \n",
       "Property_Area            -0.073278          -0.050993   -0.151566   \n",
       "Loan_Status              -0.007115           0.025545   -0.001777   \n",
       "\n",
       "                   Loan_Amount_Term  Credit_History  Property_Area  \\\n",
       "Gender                    -0.088109        0.024682      -0.020576   \n",
       "Married                   -0.110044        0.020519       0.029479   \n",
       "Dependents                -0.104441       -0.032219       0.019520   \n",
       "Education                 -0.112531       -0.075720      -0.033095   \n",
       "Self_Employed             -0.028340       -0.016306      -0.052259   \n",
       "ApplicantIncome           -0.021801        0.011250      -0.073278   \n",
       "CoapplicantIncome         -0.005052       -0.003105      -0.050993   \n",
       "LoanAmount                 0.028930       -0.005624      -0.151566   \n",
       "Loan_Amount_Term           1.000000        0.024302      -0.067434   \n",
       "Credit_History             0.024302        1.000000      -0.003404   \n",
       "Property_Area             -0.067434       -0.003404       1.000000   \n",
       "Loan_Status                0.004054        0.545934       0.016778   \n",
       "\n",
       "                   Loan_Status  \n",
       "Gender                0.052533  \n",
       "Married               0.098560  \n",
       "Dependents            0.018981  \n",
       "Education            -0.088699  \n",
       "Self_Employed        -0.018705  \n",
       "ApplicantIncome      -0.007115  \n",
       "CoapplicantIncome     0.025545  \n",
       "LoanAmount           -0.001777  \n",
       "Loan_Amount_Term      0.004054  \n",
       "Credit_History        0.545934  \n",
       "Property_Area         0.016778  \n",
       "Loan_Status           1.000000  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Loan_Status', axis=1)  # Features\n",
    "y = df['Loan_Status']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.8181818181818182\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.52      0.66        52\n",
      "           1       0.80      0.97      0.88       102\n",
      "\n",
      "    accuracy                           0.82       154\n",
      "   macro avg       0.85      0.74      0.77       154\n",
      "weighted avg       0.83      0.82      0.80       154\n",
      "\n",
      "Model: SVM\n",
      "Accuracy: 0.8051948051948052\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.52      0.64        52\n",
      "           1       0.80      0.95      0.87       102\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.82      0.74      0.75       154\n",
      "weighted avg       0.81      0.81      0.79       154\n",
      "\n",
      "Model: KNN\n",
      "Accuracy: 0.8051948051948052\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.56      0.66        52\n",
      "           1       0.81      0.93      0.86       102\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.81      0.74      0.76       154\n",
      "weighted avg       0.81      0.81      0.79       154\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.7142857142857143\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56        52\n",
      "           1       0.77      0.80      0.79       102\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.68      0.67      0.67       154\n",
      "weighted avg       0.71      0.71      0.71       154\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Accuracy: 0.7857142857142857\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.54      0.63        52\n",
      "           1       0.79      0.91      0.85       102\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.78      0.73      0.74       154\n",
      "weighted avg       0.78      0.79      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "        ('Logistic Regression', LogisticRegression()),\n",
    "        ('SVM', SVC()),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('Decision Tree', DecisionTreeClassifier()),\n",
    "        ('Random Forest',RandomForestClassifier())\n",
    "    ]\n",
    "    \n",
    "for name, model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        print(f\"Model: {name}\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.803921568627451\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.41      0.57       112\n",
      "           1       0.79      0.98      0.87       245\n",
      "\n",
      "    accuracy                           0.80       357\n",
      "   macro avg       0.85      0.70      0.72       357\n",
      "weighted avg       0.83      0.80      0.78       357\n",
      "\n",
      "Model: SVM\n",
      "Accuracy: 0.8207282913165266\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.46      0.62       112\n",
      "           1       0.80      0.98      0.88       245\n",
      "\n",
      "    accuracy                           0.82       357\n",
      "   macro avg       0.86      0.72      0.75       357\n",
      "weighted avg       0.84      0.82      0.80       357\n",
      "\n",
      "Model: KNN\n",
      "Accuracy: 0.8235294117647058\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.52      0.65       112\n",
      "           1       0.81      0.96      0.88       245\n",
      "\n",
      "    accuracy                           0.82       357\n",
      "   macro avg       0.84      0.74      0.77       357\n",
      "weighted avg       0.83      0.82      0.81       357\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       112\n",
      "           1       1.00      1.00      1.00       245\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       112\n",
      "           1       1.00      1.00      1.00       245\n",
      "\n",
      "    accuracy                           1.00       357\n",
      "   macro avg       1.00      1.00      1.00       357\n",
      "weighted avg       1.00      1.00      1.00       357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For Training Score\n",
    "models = [\n",
    "        ('Logistic Regression', LogisticRegression()),\n",
    "        ('SVM', SVC()),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('Decision Tree', DecisionTreeClassifier()),\n",
    "        ('Random Forest',RandomForestClassifier())\n",
    "    ]\n",
    "    \n",
    "for name, model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        \n",
    "        print(f\"Model: {name}\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_train,y_pred_train))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Best Parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Accuracy: 0.8181818181818182\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.52      0.66        52\n",
      "           1       0.80      0.97      0.88       102\n",
      "\n",
      "    accuracy                           0.82       154\n",
      "   macro avg       0.85      0.74      0.77       154\n",
      "weighted avg       0.83      0.82      0.80       154\n",
      "\n",
      "==================================================\n",
      "Model: SVM\n",
      "Best Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Accuracy: 0.8116883116883117\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.54      0.66        52\n",
      "           1       0.80      0.95      0.87       102\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.83      0.74      0.76       154\n",
      "weighted avg       0.82      0.81      0.80       154\n",
      "\n",
      "==================================================\n",
      "Model: KNN\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 7, 'p': 1, 'weights': 'uniform'}\n",
      "Accuracy: 0.8051948051948052\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.52      0.64        52\n",
      "           1       0.80      0.95      0.87       102\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.82      0.74      0.75       154\n",
      "weighted avg       0.81      0.81      0.79       154\n",
      "\n",
      "==================================================\n",
      "Model: Decision Tree\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_split': 10}\n",
      "Accuracy: 0.6688311688311688\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.54      0.52        52\n",
      "           1       0.76      0.74      0.75       102\n",
      "\n",
      "    accuracy                           0.67       154\n",
      "   macro avg       0.63      0.64      0.63       154\n",
      "weighted avg       0.67      0.67      0.67       154\n",
      "\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Best Parameters: {'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.8181818181818182\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.52      0.66        52\n",
      "           1       0.80      0.97      0.88       102\n",
      "\n",
      "    accuracy                           0.82       154\n",
      "   macro avg       0.85      0.74      0.77       154\n",
      "weighted avg       0.83      0.82      0.80       154\n",
      "\n",
      "==================================================\n",
      "Best Model: Logistic Regression\n",
      "Best Parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best Accuracy: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "# Model Selection and Hyperparameter Tuning\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "best_params = None\n",
    "models = [('Logistic Regression', LogisticRegression(), {'C': [0.001, 0.01, 0.1, 1, 10], \n",
    "                                                       'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                                                       'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                                                       'max_iter': [100, 200, 300]}),\n",
    "        ('SVM', SVC(), {'C': [0.1, 1, 10], \n",
    "                        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], \n",
    "                        'gamma': ['scale', 'auto']}),\n",
    "        ('KNN', KNeighborsClassifier(), {'n_neighbors': [3, 5, 7],\n",
    "                                         'weights': ['uniform', 'distance'],\n",
    "                                         'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                                         'p': [1, 2]}),\n",
    "        ('Decision Tree', DecisionTreeClassifier(), {'max_depth': [None, 10, 20], \n",
    "                                                     'min_samples_split': [2, 5, 10]}),\n",
    "        ('Random Forest',RandomForestClassifier(),{'n_estimators': [50, 100, 200],\n",
    "                                                   'max_depth': [None, 10, 20],\n",
    "                                                   'min_samples_split': [2, 5, 10],\n",
    "                                                   'min_samples_leaf': [1, 2, 4],\n",
    "                                                   'max_features': ['auto', 'sqrt', 'log2']})\n",
    "\n",
    "    ]\n",
    "for name, model, param_grid in models:\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train,y_train)\n",
    "        \n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"=\"*50)\n",
    "        \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = name\n",
    "        best_params = grid_search.best_params_\n",
    "    \n",
    "print(\"Best Model:\", best_model)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60        52\n",
      "           1       0.79      0.82      0.81       102\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.71      0.70      0.70       154\n",
      "weighted avg       0.74      0.74      0.74       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bg=BaggingClassifier(DecisionTreeClassifier())\n",
    "bg.fit(X_train,y_train)\n",
    "ypred=bg.predict(X_test)\n",
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.52      0.64        52\n",
      "           1       0.80      0.95      0.87       102\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.82      0.74      0.75       154\n",
      "weighted avg       0.81      0.81      0.79       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bg=BaggingClassifier(SVC())\n",
    "bg.fit(X_train,y_train)\n",
    "ypred=bg.predict(X_test)\n",
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.52      0.61        52\n",
      "           1       0.79      0.91      0.85       102\n",
      "\n",
      "    accuracy                           0.78       154\n",
      "   macro avg       0.77      0.72      0.73       154\n",
      "weighted avg       0.78      0.78      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bg=BaggingClassifier(KNeighborsClassifier())\n",
    "bg.fit(X_train,y_train)\n",
    "ypred=bg.predict(X_test)\n",
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.54      0.65        52\n",
      "           1       0.80      0.94      0.86       102\n",
      "\n",
      "    accuracy                           0.81       154\n",
      "   macro avg       0.81      0.74      0.76       154\n",
      "weighted avg       0.81      0.81      0.79       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bg=BaggingClassifier(RandomForestClassifier())\n",
    "bg.fit(X_train,y_train)\n",
    "ypred=bg.predict(X_test)\n",
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus= RandomUnderSampler(random_state=1,replacement=True)\n",
    "x_rus,y_rus=rus.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_rus, y_rus, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.6161616161616161\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.43      0.55        53\n",
      "           1       0.56      0.83      0.67        46\n",
      "\n",
      "    accuracy                           0.62        99\n",
      "   macro avg       0.65      0.63      0.61        99\n",
      "weighted avg       0.66      0.62      0.60        99\n",
      "\n",
      "Model: SVM\n",
      "Accuracy: 0.6666666666666666\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.47      0.60        53\n",
      "           1       0.59      0.89      0.71        46\n",
      "\n",
      "    accuracy                           0.67        99\n",
      "   macro avg       0.71      0.68      0.66        99\n",
      "weighted avg       0.72      0.67      0.65        99\n",
      "\n",
      "Model: KNN\n",
      "Accuracy: 0.6767676767676768\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.53      0.64        53\n",
      "           1       0.61      0.85      0.71        46\n",
      "\n",
      "    accuracy                           0.68        99\n",
      "   macro avg       0.70      0.69      0.67        99\n",
      "weighted avg       0.71      0.68      0.67        99\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.7171717171717171\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.71        53\n",
      "           1       0.67      0.78      0.72        46\n",
      "\n",
      "    accuracy                           0.72        99\n",
      "   macro avg       0.72      0.72      0.72        99\n",
      "weighted avg       0.73      0.72      0.72        99\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.696969696969697\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69        53\n",
      "           1       0.64      0.78      0.71        46\n",
      "\n",
      "    accuracy                           0.70        99\n",
      "   macro avg       0.71      0.70      0.70        99\n",
      "weighted avg       0.71      0.70      0.70        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "        ('Logistic Regression', LogisticRegression()),\n",
    "        ('SVM', SVC()),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('Decision Tree', DecisionTreeClassifier()),\n",
    "        ('Random Forest',RandomForestClassifier())\n",
    "    ]\n",
    "    \n",
    "for name, model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        print(f\"Model: {name}\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros=RandomOverSampler(random_state=1)\n",
    "x_ros,y_ros=ros.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_ros, y_ros, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.7081339712918661\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.61      0.66        99\n",
      "           1       0.69      0.80      0.74       110\n",
      "\n",
      "    accuracy                           0.71       209\n",
      "   macro avg       0.71      0.70      0.70       209\n",
      "weighted avg       0.71      0.71      0.70       209\n",
      "\n",
      "Model: SVM\n",
      "Accuracy: 0.7272727272727273\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.65      0.69        99\n",
      "           1       0.72      0.80      0.76       110\n",
      "\n",
      "    accuracy                           0.73       209\n",
      "   macro avg       0.73      0.72      0.72       209\n",
      "weighted avg       0.73      0.73      0.73       209\n",
      "\n",
      "Model: KNN\n",
      "Accuracy: 0.7799043062200957\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77        99\n",
      "           1       0.81      0.76      0.79       110\n",
      "\n",
      "    accuracy                           0.78       209\n",
      "   macro avg       0.78      0.78      0.78       209\n",
      "weighted avg       0.78      0.78      0.78       209\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.7703349282296651\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.89      0.79        99\n",
      "           1       0.87      0.66      0.75       110\n",
      "\n",
      "    accuracy                           0.77       209\n",
      "   macro avg       0.79      0.78      0.77       209\n",
      "weighted avg       0.79      0.77      0.77       209\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.8421052631578947\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84        99\n",
      "           1       0.88      0.81      0.84       110\n",
      "\n",
      "    accuracy                           0.84       209\n",
      "   macro avg       0.84      0.84      0.84       209\n",
      "weighted avg       0.85      0.84      0.84       209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "        ('Logistic Regression', LogisticRegression()),\n",
    "        ('SVM', SVC()),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('Decision Tree', DecisionTreeClassifier()),\n",
    "        ('Random Forest',RandomForestClassifier())\n",
    "    ]\n",
    "    \n",
    "for name, model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        print(f\"Model: {name}\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Best Parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Accuracy: 0.7607655502392344\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.53      0.68        99\n",
      "           1       0.69      0.97      0.81       110\n",
      "\n",
      "    accuracy                           0.76       209\n",
      "   macro avg       0.82      0.75      0.74       209\n",
      "weighted avg       0.81      0.76      0.75       209\n",
      "\n",
      "==================================================\n",
      "Model: SVM\n",
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.7511961722488039\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74        99\n",
      "           1       0.77      0.75      0.76       110\n",
      "\n",
      "    accuracy                           0.75       209\n",
      "   macro avg       0.75      0.75      0.75       209\n",
      "weighted avg       0.75      0.75      0.75       209\n",
      "\n",
      "==================================================\n",
      "Model: KNN\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "Accuracy: 0.8277511961722488\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        99\n",
      "           1       0.87      0.79      0.83       110\n",
      "\n",
      "    accuracy                           0.83       209\n",
      "   macro avg       0.83      0.83      0.83       209\n",
      "weighted avg       0.83      0.83      0.83       209\n",
      "\n",
      "==================================================\n",
      "Model: Decision Tree\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2}\n",
      "Accuracy: 0.7607655502392344\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.88      0.78        99\n",
      "           1       0.86      0.65      0.74       110\n",
      "\n",
      "    accuracy                           0.76       209\n",
      "   macro avg       0.78      0.77      0.76       209\n",
      "weighted avg       0.78      0.76      0.76       209\n",
      "\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy: 0.8277511961722488\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83        99\n",
      "           1       0.88      0.78      0.83       110\n",
      "\n",
      "    accuracy                           0.83       209\n",
      "   macro avg       0.83      0.83      0.83       209\n",
      "weighted avg       0.83      0.83      0.83       209\n",
      "\n",
      "==================================================\n",
      "Best Model: KNN\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "Best Accuracy: 0.8277511961722488\n"
     ]
    }
   ],
   "source": [
    "# Model Selection and Hyperparameter Tuning\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "best_params = None\n",
    "models = [('Logistic Regression', LogisticRegression(), {'C': [0.001, 0.01, 0.1, 1, 10], \n",
    "                                                       'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                                                       'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                                                       'max_iter': [100, 200, 300]}),\n",
    "        ('SVM', SVC(), {'C': [0.1, 1, 10], \n",
    "                        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], \n",
    "                        'gamma': ['scale', 'auto']}),\n",
    "        ('KNN', KNeighborsClassifier(), {'n_neighbors': [3, 5, 7],\n",
    "                                         'weights': ['uniform', 'distance'],\n",
    "                                         'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                                         'p': [1, 2]}),\n",
    "        ('Decision Tree', DecisionTreeClassifier(), {'max_depth': [None, 10, 20], \n",
    "                                                     'min_samples_split': [2, 5, 10]}),\n",
    "        ('Random Forest',RandomForestClassifier(),{'n_estimators': [50, 100, 200],\n",
    "                                                   'max_depth': [None, 10, 20],\n",
    "                                                   'min_samples_split': [2, 5, 10],\n",
    "                                                   'min_samples_leaf': [1, 2, 4],\n",
    "                                                   'max_features': ['auto', 'sqrt', 'log2']})\n",
    "\n",
    "    ]\n",
    "for name, model, param_grid in models:\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train,y_train)\n",
    "        \n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"=\"*50)\n",
    "        \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = name\n",
    "        best_params = grid_search.best_params_\n",
    "    \n",
    "print(\"Best Model:\", best_model)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain1,ytrain1=sm.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.6883116883116883\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54        52\n",
      "           1       0.76      0.76      0.76       102\n",
      "\n",
      "    accuracy                           0.69       154\n",
      "   macro avg       0.65      0.65      0.65       154\n",
      "weighted avg       0.69      0.69      0.69       154\n",
      "\n",
      "Model: SVM\n",
      "Accuracy: 0.7467532467532467\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.61        52\n",
      "           1       0.80      0.82      0.81       102\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.71      0.71       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "Model: KNN\n",
      "Accuracy: 0.6688311688311688\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.60      0.55        52\n",
      "           1       0.77      0.71      0.74       102\n",
      "\n",
      "    accuracy                           0.67       154\n",
      "   macro avg       0.64      0.65      0.64       154\n",
      "weighted avg       0.68      0.67      0.67       154\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.6428571428571429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.58      0.52        52\n",
      "           1       0.76      0.68      0.72       102\n",
      "\n",
      "    accuracy                           0.64       154\n",
      "   macro avg       0.62      0.63      0.62       154\n",
      "weighted avg       0.66      0.64      0.65       154\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.7597402597402597\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.58      0.62        52\n",
      "           1       0.80      0.85      0.82       102\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.76      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "        ('Logistic Regression', LogisticRegression()),\n",
    "        ('SVM', SVC()),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('Decision Tree', DecisionTreeClassifier()),\n",
    "        ('Random Forest',RandomForestClassifier())\n",
    "    ]\n",
    "    \n",
    "for name, model in models:\n",
    "        model.fit(xtrain1, ytrain1)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        print(f\"Model: {name}\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Best Parameters: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.7467532467532467\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.54      0.59        52\n",
      "           1       0.78      0.85      0.82       102\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.70      0.70       154\n",
      "weighted avg       0.74      0.75      0.74       154\n",
      "\n",
      "==================================================\n",
      "Model: SVM\n",
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.7467532467532467\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62        52\n",
      "           1       0.81      0.81      0.81       102\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.72      0.71      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "==================================================\n",
      "Model: KNN\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "Accuracy: 0.7077922077922078\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.57        52\n",
      "           1       0.78      0.77      0.78       102\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.67      0.68      0.67       154\n",
      "weighted avg       0.71      0.71      0.71       154\n",
      "\n",
      "==================================================\n",
      "Model: Decision Tree\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_split': 2}\n",
      "Accuracy: 0.6493506493506493\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.56      0.52        52\n",
      "           1       0.76      0.70      0.72       102\n",
      "\n",
      "    accuracy                           0.65       154\n",
      "   macro avg       0.62      0.63      0.62       154\n",
      "weighted avg       0.66      0.65      0.65       154\n",
      "\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Best Parameters: {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.7597402597402597\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.58      0.62        52\n",
      "           1       0.80      0.85      0.82       102\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.75      0.76      0.76       154\n",
      "\n",
      "==================================================\n",
      "Best Model: Random Forest\n",
      "Best Parameters: {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Accuracy: 0.7597402597402597\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "best_params = None\n",
    "models = [('Logistic Regression', LogisticRegression(), {'C': [0.001, 0.01, 0.1, 1, 10], \n",
    "                                                       'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                                                       'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                                                       'max_iter': [100, 200, 300]}),\n",
    "        ('SVM', SVC(), {'C': [0.1, 1, 10], \n",
    "                        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], \n",
    "                        'gamma': ['scale', 'auto']}),\n",
    "        ('KNN', KNeighborsClassifier(), {'n_neighbors': [3, 5, 7],\n",
    "                                         'weights': ['uniform', 'distance'],\n",
    "                                         'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                                         'p': [1, 2]}),\n",
    "        ('Decision Tree', DecisionTreeClassifier(), {'max_depth': [None, 10, 20], \n",
    "                                                     'min_samples_split': [2, 5, 10]}),\n",
    "        ('Random Forest',RandomForestClassifier(),{'n_estimators': [50, 100, 200],\n",
    "                                                   'max_depth': [None, 10, 20],\n",
    "                                                   'min_samples_split': [2, 5, 10],\n",
    "                                                   'min_samples_leaf': [1, 2, 4],\n",
    "                                                   'max_features': ['auto', 'sqrt', 'log2']})\n",
    "\n",
    "    ]\n",
    "for name, model, param_grid in models:\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(xtrain1,ytrain1)\n",
    "        \n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"=\"*50)\n",
    "        \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = name\n",
    "        best_params = grid_search.best_params_\n",
    "    \n",
    "print(\"Best Model:\", best_model)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample and SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_ros, y_ros, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.722488038277512\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.70        99\n",
      "           1       0.73      0.75      0.74       110\n",
      "\n",
      "    accuracy                           0.72       209\n",
      "   macro avg       0.72      0.72      0.72       209\n",
      "weighted avg       0.72      0.72      0.72       209\n",
      "\n",
      "==================================================\n",
      "Model: SVM\n",
      "Accuracy: 0.7655502392344498\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75        99\n",
      "           1       0.77      0.79      0.78       110\n",
      "\n",
      "    accuracy                           0.77       209\n",
      "   macro avg       0.77      0.76      0.76       209\n",
      "weighted avg       0.77      0.77      0.77       209\n",
      "\n",
      "==================================================\n",
      "Model: KNN\n",
      "Accuracy: 0.7751196172248804\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77        99\n",
      "           1       0.80      0.76      0.78       110\n",
      "\n",
      "    accuracy                           0.78       209\n",
      "   macro avg       0.78      0.78      0.77       209\n",
      "weighted avg       0.78      0.78      0.78       209\n",
      "\n",
      "==================================================\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.8660287081339713\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        99\n",
      "           1       0.87      0.87      0.87       110\n",
      "\n",
      "    accuracy                           0.87       209\n",
      "   macro avg       0.87      0.87      0.87       209\n",
      "weighted avg       0.87      0.87      0.87       209\n",
      "\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Accuracy: 0.8755980861244019\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86        99\n",
      "           1       0.86      0.91      0.88       110\n",
      "\n",
      "    accuracy                           0.88       209\n",
      "   macro avg       0.88      0.87      0.87       209\n",
      "weighted avg       0.88      0.88      0.88       209\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "        ('Logistic Regression', LogisticRegression()),\n",
    "        ('SVM', SVC()),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('Decision Tree', DecisionTreeClassifier()),\n",
    "        ('Random Forest',RandomForestClassifier())\n",
    "    ]\n",
    "    \n",
    "for name, model in models:\n",
    "        model.fit(xtrain1, ytrain1)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        print(f\"Model: {name}\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "        print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Best Parameters: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.7416267942583732\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71        99\n",
      "           1       0.73      0.81      0.77       110\n",
      "\n",
      "    accuracy                           0.74       209\n",
      "   macro avg       0.74      0.74      0.74       209\n",
      "weighted avg       0.74      0.74      0.74       209\n",
      "\n",
      "==================================================\n",
      "Model: SVM\n",
      "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.7799043062200957\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76        99\n",
      "           1       0.78      0.82      0.80       110\n",
      "\n",
      "    accuracy                           0.78       209\n",
      "   macro avg       0.78      0.78      0.78       209\n",
      "weighted avg       0.78      0.78      0.78       209\n",
      "\n",
      "==================================================\n",
      "Model: KNN\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "Accuracy: 0.861244019138756\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85        99\n",
      "           1       0.86      0.87      0.87       110\n",
      "\n",
      "    accuracy                           0.86       209\n",
      "   macro avg       0.86      0.86      0.86       209\n",
      "weighted avg       0.86      0.86      0.86       209\n",
      "\n",
      "==================================================\n",
      "Model: Decision Tree\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_split': 2}\n",
      "Accuracy: 0.84688995215311\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84        99\n",
      "           1       0.86      0.85      0.85       110\n",
      "\n",
      "    accuracy                           0.85       209\n",
      "   macro avg       0.85      0.85      0.85       209\n",
      "weighted avg       0.85      0.85      0.85       209\n",
      "\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Best Parameters: {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.8755980861244019\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86        99\n",
      "           1       0.86      0.91      0.88       110\n",
      "\n",
      "    accuracy                           0.88       209\n",
      "   macro avg       0.88      0.87      0.87       209\n",
      "weighted avg       0.88      0.88      0.88       209\n",
      "\n",
      "==================================================\n",
      "Best Model: Random Forest\n",
      "Best Parameters: {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Accuracy: 0.8755980861244019\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "best_params = None\n",
    "models = [('Logistic Regression', LogisticRegression(), {'C': [0.001, 0.01, 0.1, 1, 10], \n",
    "                                                       'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                                                       'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                                                       'max_iter': [100, 200, 300]}),\n",
    "        ('SVM', SVC(), {'C': [0.1, 1, 10], \n",
    "                        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], \n",
    "                        'gamma': ['scale', 'auto']}),\n",
    "        ('KNN', KNeighborsClassifier(), {'n_neighbors': [3, 5, 7],\n",
    "                                         'weights': ['uniform', 'distance'],\n",
    "                                         'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                                         'p': [1, 2]}),\n",
    "        ('Decision Tree', DecisionTreeClassifier(), {'max_depth': [None, 10, 20], \n",
    "                                                     'min_samples_split': [2, 5, 10]}),\n",
    "        ('Random Forest',RandomForestClassifier(),{'n_estimators': [50, 100, 200],\n",
    "                                                   'max_depth': [None, 10, 20],\n",
    "                                                   'min_samples_split': [2, 5, 10],\n",
    "                                                   'min_samples_leaf': [1, 2, 4],\n",
    "                                                   'max_features': ['auto', 'sqrt', 'log2']})\n",
    "\n",
    "    ]\n",
    "for name, model, param_grid in models:\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(xtrain1,ytrain1)\n",
    "        \n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"=\"*50)\n",
    "        \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = name\n",
    "        best_params = grid_search.best_params_\n",
    "    \n",
    "print(\"Best Model:\", best_model)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86        99\n",
      "           1       0.87      0.89      0.88       110\n",
      "\n",
      "    accuracy                           0.87       209\n",
      "   macro avg       0.87      0.87      0.87       209\n",
      "weighted avg       0.87      0.87      0.87       209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bg=BaggingClassifier(KNeighborsClassifier(algorithm='auto', n_neighbors= 7, p= 1, weights= 'distance'))\n",
    "bg.fit(xtrain1,ytrain1)\n",
    "ypred=bg.predict(X_test)\n",
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74        99\n",
      "           1       0.76      0.78      0.77       110\n",
      "\n",
      "    accuracy                           0.76       209\n",
      "   macro avg       0.76      0.75      0.75       209\n",
      "weighted avg       0.76      0.76      0.76       209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bg=BaggingClassifier(SVC())\n",
    "bg.fit(xtrain1,ytrain1)\n",
    "ypred=bg.predict(X_test)\n",
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88        99\n",
      "           1       0.87      0.92      0.89       110\n",
      "\n",
      "    accuracy                           0.89       209\n",
      "   macro avg       0.89      0.88      0.88       209\n",
      "weighted avg       0.89      0.89      0.88       209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bg=BaggingClassifier(RandomForestClassifier())\n",
    "bg.fit(xtrain1,ytrain1)\n",
    "ypred=bg.predict(X_test)\n",
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
